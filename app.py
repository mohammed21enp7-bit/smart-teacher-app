import streamlit as st
from openai import OpenAI
import json
import os
import datetime
import base64
import PyPDF2
import sys

# --- ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ø§Ù„Ø±ØµÙŠØ¯ (Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©) ---
LIMITS = {
    "free": 5,      # Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø§Ø¯ÙŠ
    "VIP10": 10,    # ÙƒÙˆØ¯ Ù„Ù„Ø£ØµØ¯Ù‚Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø±Ø¨ÙŠÙ†
    "ADMIN": 1000   # ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ
}

# --- ğŸ› ï¸ Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© ØªØ±Ù…ÙŠØ² Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ---
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù…Ø¹Ù‡Ø¯ÙŠ - Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ğŸ¨ Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¹ØµØ±ÙŠ (CSS) - ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; }
    div[data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #e3f2fd !important;
        border: 1px solid #bbdefb !important;
        color: #000000 !important;
    }
    div[data-testid="stChatMessage"]:nth-child(even) {
        background-color: #ffffff !important;
        border: 1px solid #e0e0e0 !important;
        color: #000000 !important;
    }
    div[data-testid="stChatMessage"] p,
    div[data-testid="stChatMessage"] h1,
    div[data-testid="stChatMessage"] h2,
    div[data-testid="stChatMessage"] h3,
    div[data-testid="stChatMessage"] li,
    div[data-testid="stChatMessage"] div {
        color: #000000 !important;
    }
    div.stButton > button {
        background: linear-gradient(45deg, #2563eb, #0ea5e9);
        color: white !important;
        border: none;
        border-radius: 12px;
        transition: transform 0.2s;
    }
    div.stButton > button:hover {
        transform: scale(1.02);
    }
    @media (prefers-color-scheme: dark) {
        .stApp { background-color: #0e1117; }
        [data-testid="stSidebar"] { background-color: #161b22; border-right: 1px solid #30363d; }
        h1, h2, h3 { color: #e6edf3; }
        .stTextInput input { color: white !important; }
    }
</style>
""", unsafe_allow_html=True)

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
HISTORY_FILE = "chat_history.json"

# Ù…ÙŠØ²Ø© Ø§Ù„Ø¹Ø¯Ø§Ø¯ (ØªØ®Ø²Ù† ÙÙŠ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
if "usage_counter" not in st.session_state:
    st.session_state.usage_counter = 0

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_history(history_dict):
    history_to_save = {}
    for k, v in history_dict.items():
        clean_messages = []
        for msg in v["messages"]:
            clean_msg = {key: val for key, val in msg.items() if key not in ["audio_content", "generated_image"]}
            clean_messages.append(clean_msg)
        history_to_save[k] = {"title": v["title"], "messages": clean_messages}
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history_to_save, f, ensure_ascii=True, indent=4)
    except Exception as e:
        print(f"Warning: Could not save history: {e}")

def encode_image(image_file):
    return base64.b64encode(image_file.getvalue()).decode('utf-8')

def get_pdf_text(pdf_file):
    text = ""
    try:
        reader = PyPDF2.PdfReader(pdf_file)
        for page in reader.pages:
            text += page.extract_text() + "\n"
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}"
    return text

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®
if "history" not in st.session_state:
    st.session_state.history = load_history()

if "current_chat_id" not in st.session_state:
    new_id = str(datetime.datetime.now())
    st.session_state.current_chat_id = new_id
    st.session_state.history[new_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}

current_id = st.session_state.current_chat_id
if current_id not in st.session_state.history:
    st.session_state.history[current_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}

st.session_state.messages = st.session_state.history[current_id]["messages"]

if "suggestion_clicked" not in st.session_state:
    st.session_state.suggestion_clicked = None

# --- Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø¢Ù…Ù† ---
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
except Exception as e:
    st.error("Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù…ÙØªØ§Ø­ OpenAI")
    st.stop()

# 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
with st.sidebar:
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙØµÙ„")
    subject = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø©:", ["Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡", "Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡", "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "Ø§Ù„Ø£Ø­ÙŠØ§Ø¡", "Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"])
    level = st.selectbox("Ø§Ù„ØµÙ:", ["Ø§Ù„Ø«Ø§Ù„Ø« Ù…ØªÙˆØ³Ø·", "Ø§Ù„Ø±Ø§Ø¨Ø¹ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø®Ø§Ù…Ø³ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø³Ø§Ø¯Ø³ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø³Ø§Ø¯Ø³ Ø£Ø¯Ø¨ÙŠ"])
    
    st.markdown("---")
    # Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø¯Ø§Ø¯ ÙÙŠ Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø±
    input_code = st.text_input("ğŸ”‘ ÙƒÙˆØ¯ Ø§Ù„ØªÙØ¹ÙŠÙ„ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª:", type="password")
    current_limit = LIMITS.get(input_code, LIMITS["free"])
    
    st.write(f"ğŸ“Š Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙƒ: {st.session_state.usage_counter} Ù…Ù† {current_limit}")
    st.progress(min(st.session_state.usage_counter / current_limit, 1.0))
    
    st.markdown("---")
    enable_voice = st.toggle("ğŸ”Š Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´Ø±Ø­", value=False)
    enable_image_gen = st.toggle("ğŸ¨ Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ", value=False)
    
    st.markdown("---")
    if st.button("â• Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©", type="primary"):
        new_id = str(datetime.datetime.now())
        st.session_state.current_chat_id = new_id
        st.session_state.history[new_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}
        st.session_state.suggestion_clicked = None
        st.rerun()

    st.markdown("### ğŸ“‚ Ø§Ù„Ø³Ø¬Ù„")
    history_keys = reversed(list(st.session_state.history.keys()))
    for chat_id in history_keys:
        chat_data = st.session_state.history[chat_id]
        if len(chat_data["messages"]) > 0:
            if st.button(f"ğŸ“„ {chat_data['title']}", key=chat_id):
                st.session_state.current_chat_id = chat_id
                st.session_state.suggestion_clicked = None
                st.rerun()

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title(f"ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ: {subject}")

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for message in st.session_state.messages:
    role = message["role"]
    with st.chat_message(role):
        st.markdown(message["content"])
        if "audio_content" in message:
            st.audio(message["audio_content"], format="audio/mp3")
        if "generated_image" in message:
            st.image(message["generated_image"], caption="Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ ğŸ¨")

# Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© (Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª)
st.markdown("---")
voice_text = ""
uploaded_image = None
audio_value = None
uploaded_pdf = None
pdf_content = ""

with st.expander("ğŸ“ Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª (ØµÙˆØªØŒ ØµÙˆØ±Ø©ØŒ PDF)", expanded=False):
    c1, c2, c3 = st.columns(3)
    with c1:
        audio_value = st.audio_input("ØªØ³Ø¬ÙŠÙ„")
        if audio_value:
            try:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=("audio.wav", audio_value, "audio/wav"), language="ar")
                voice_text = transcript.text
            except: pass
    with c2:
        uploaded_image = st.file_uploader("ØµÙˆØ±Ø©", type=["jpg", "png"])
    with c3:
        uploaded_pdf = st.file_uploader("PDF", type=["pdf"])
        if uploaded_pdf:
            pdf_content = get_pdf_text(uploaded_pdf)

# Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
prompt_text = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ...")
final_prompt = None

if st.session_state.suggestion_clicked:
    final_prompt = st.session_state.suggestion_clicked
    st.session_state.suggestion_clicked = None
elif prompt_text:
    final_prompt = prompt_text
elif voice_text:
    final_prompt = voice_text

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„
if final_prompt:
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ø¯Ø§Ø¯
    if st.session_state.usage_counter >= current_limit:
        st.error(f"ğŸ›‘ Ø¹Ø°Ø±Ø§Ù‹! Ù„Ù‚Ø¯ ÙˆØµÙ„Øª Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({current_limit} Ù…Ø­Ø§ÙˆÙ„Ø§Øª). Ø§Ø·Ù„Ø¨ ÙƒÙˆØ¯ Ø§Ù„ØªÙØ¹ÙŠÙ„ Ù…Ù† Ø§Ù„Ø£Ø³ØªØ§Ø°.")
    else:
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        with st.chat_message("user"):
            st.markdown(final_prompt)
        
        # Ù†Ø¸Ø§Ù… Ø§Ù„Ù€ System Prompt
        pdf_instruction = f"ğŸ“ PDF content:\n{pdf_content[:5000]}" if pdf_content else ""
        system_prompt = f"Ø£Ù†Øª Ù…Ø¯Ø±Ø³ {subject} Ù„Ù„ØµÙ {level}. {pdf_instruction}. Ø§Ø´Ø±Ø­ Ø¨Ù„Ù‡Ø¬Ø© Ø¹Ø±Ø§Ù‚ÙŠØ©. Ø§Ø³ØªØ®Ø¯Ù… LaTeX. Ù„Ùˆ Ø·Ù„Ø¨ Ø±Ø³Ù…Ø© Ø§ÙƒØªØ¨ IMAGE_REQ. Ø§Ù‚ØªØ±Ø­ 3 Ø£Ø³Ø¦Ù„Ø© Ø¨ÙØ§ØµÙ„ ###SUGGESTIONS###."
        
        user_content = [{"type": "text", "text": final_prompt}]
        if uploaded_image:
            base64_image = encode_image(uploaded_image)
            user_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}})

        # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù€ OpenAI
        with st.chat_message("assistant"):
            with st.spinner('ğŸ¤”'):
                try:
                    response = client.chat.completions.create(model="gpt-4o-mini", messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_content}
                    ])
                    full_response = response.choices[0].message.content
                    
                    # ÙØµÙ„ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª (Ù…Ù† ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ)
                    if "###SUGGESTIONS###" in full_response:
                        answer_display, suggestions_part = full_response.split("###SUGGESTIONS###")
                        suggestions_list = [s.strip() for s in suggestions_part.strip().split('\n') if s.strip()]
                    else:
                        answer_display, suggestions_list = full_response, []

                    st.markdown(answer_display)
                    current_msg = {"role": "assistant", "content": answer_display}

                    # Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ø±Ø³Ù… (Ù…Ù† ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ)
                    if enable_voice:
                        speech = client.audio.speech.create(model="tts-1", voice="onyx", input=answer_display[:500])
                        current_msg["audio_content"] = speech.content
                        st.audio(current_msg["audio_content"])

                    if enable_image_gen and "IMAGE_REQ" in full_response:
                        img = client.images.generate(model="dall-e-3", prompt=f"Educational diagram: {final_prompt}", size="1024x1024")
                        current_msg["generated_image"] = img.data[0].url
                        st.image(current_msg["generated_image"])

                    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                    st.session_state.messages.append(current_msg)
                    st.session_state.usage_counter += 1 # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø¯Ø§Ø¯
                    save_history(st.session_state.history)
                    st.rerun()

                except Exception as e:
                    st.error(f"Error: {e}")
