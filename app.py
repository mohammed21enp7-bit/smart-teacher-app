import streamlit as st
from openai import OpenAI
import json
import os
import datetime
import base64
import PyPDF2
import sys

# --- ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª ---
LIMITS = {"free": 5, "VIP10": 15, "ADMIN": 1000}

# Ø¥ØµÙ„Ø§Ø­ ØªØ±Ù…ÙŠØ² Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
try: sys.stdout.reconfigure(encoding='utf-8')
except: pass

st.set_page_config(page_title="Ù…Ø¹Ù‡Ø¯ÙŠ - Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ“", layout="wide")

# --- ğŸ¨ Ø§Ù„ØªØµÙ…ÙŠÙ… (CSS) - ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø¯ÙˆÙ† Ù†Ù‚Øµ ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; }
    div[data-testid="stChatMessage"]:nth-child(odd) { background-color: #e3f2fd !important; border: 1px solid #bbdefb !important; color: #000 !important; }
    div[data-testid="stChatMessage"]:nth-child(even) { background-color: #ffffff !important; border: 1px solid #e0e0e0 !important; color: #000 !important; }
    div[data-testid="stChatMessage"] p { color: #000000 !important; }
    div.stButton > button { background: linear-gradient(45deg, #2563eb, #0ea5e9); color: white !important; border-radius: 12px; }
</style>
""", unsafe_allow_html=True)

# --- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
HISTORY_FILE = "chat_history.json"
if "usage_counter" not in st.session_state: st.session_state.usage_counter = 0

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f: return json.load(f)
        except: return {}
    return {}

def save_history(history_dict):
    to_save = {}
    for k, v in history_dict.items():
        msgs = [{"role": m["role"], "content": m["content"]} for m in v["messages"] if "audio_content" not in m]
        to_save[k] = {"title": v["title"], "messages": msgs}
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f: json.dump(to_save, f, ensure_ascii=False, indent=4)
    except: pass

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„Ø¬Ù„Ø³Ø©
if "history" not in st.session_state: st.session_state.history = load_history()
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = str(datetime.datetime.now())
    st.session_state.history[st.session_state.current_chat_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}

current_id = st.session_state.current_chat_id
st.session_state.messages = st.session_state.history[current_id]["messages"]
if "suggestion_clicked" not in st.session_state: st.session_state.suggestion_clicked = None
if "quiz_trigger" not in st.session_state: st.session_state.quiz_trigger = False

# --- Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI ---
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø§Ø³ØªØ¹Ø§Ø¯Ø© ÙƒÙ„ Ø§Ù„Ø£Ø²Ø±Ø§Ø±) ---
with st.sidebar:
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙØµÙ„")
    subject = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø©:", ["Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡", "Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡", "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "Ø§Ù„Ø£Ø­ÙŠØ§Ø¡", "Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"])
    level = st.selectbox("Ø§Ù„ØµÙ:", ["Ø§Ù„Ø«Ø§Ù„Ø« Ù…ØªÙˆØ³Ø·", "Ø§Ù„Ø±Ø§Ø¨Ø¹ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø®Ø§Ù…Ø³ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø³Ø§Ø¯Ø³ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø³Ø§Ø¯Ø³ Ø£Ø¯Ø¨ÙŠ"])
    
    st.markdown("---")
    access_code = st.text_input("ğŸ”‘ ÙƒÙˆØ¯ Ø§Ù„ØªÙØ¹ÙŠÙ„:", type="password")
    user_limit = LIMITS.get(access_code, LIMITS["free"])
    st.write(f"ğŸ“Š Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª: {st.session_state.usage_counter} / {user_limit}")
    st.progress(min(st.session_state.usage_counter / user_limit, 1.0))
    
    st.markdown("---")
    enable_voice = st.toggle("ğŸ”Š Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´Ø±Ø­", value=False)
    enable_image_gen = st.toggle("ğŸ¨ Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ", value=False)
    
    if st.button("â• Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©", type="primary"):
        st.session_state.current_chat_id = str(datetime.datetime.now())
        st.session_state.history[st.session_state.current_chat_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}
        st.rerun()

    if st.button("ğŸ“ Ø§Ù…ØªØ­Ø§Ù† Ø³Ø±ÙŠØ¹"):
        st.session_state.quiz_trigger = True

    st.markdown("### ğŸ“‚ Ø§Ù„Ø³Ø¬Ù„")
    for chat_id in reversed(list(st.session_state.history.keys())):
        if len(st.session_state.history[chat_id]["messages"]) > 0:
            if st.button(f"ğŸ“„ {st.session_state.history[chat_id]['title'][:20]}", key=chat_id):
                st.session_state.current_chat_id = chat_id
                st.rerun()

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title(f"ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ: {subject}")

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "audio_content" in msg: st.audio(msg["audio_content"], format="audio/mp3")

# Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª
with st.expander("ğŸ“ Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª"):
    c1, c2, c3 = st.columns(3)
    with c1: audio_val = st.audio_input("ØªØ³Ø¬ÙŠÙ„")
    with c2: up_img = st.file_uploader("ØµÙˆØ±Ø©", type=["jpg", "png"])
    with c3: up_pdf = st.file_uploader("PDF", type=["pdf"])

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
prompt_text = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ...")
final_prompt = None

if st.session_state.suggestion_clicked:
    final_prompt = st.session_state.suggestion_clicked
    st.session_state.suggestion_clicked = None
elif st.session_state.quiz_trigger:
    final_prompt = f"Ø§Ø¹Ù…Ù„ Ù„ÙŠ Ø§Ù…ØªØ­Ø§Ù† Ø³Ø±ÙŠØ¹ ÙˆÙ‚ØµÙŠØ± ÙÙŠ Ù…Ø§Ø¯Ø© {subject}."
    st.session_state.quiz_trigger = False
elif prompt_text:
    final_prompt = prompt_text
elif audio_val:
    try:
        transcript = client.audio.transcriptions.create(model="whisper-1", file=("audio.wav", audio_val, "audio/wav"), language="ar")
        final_prompt = transcript.text
    except: pass

# --- ØªÙ†ÙÙŠØ° Ø§Ù„Ø·Ù„Ø¨ ---
if final_prompt:
    if st.session_state.usage_counter >= user_limit:
        st.error(f"ğŸ›‘ Ø¹Ø°Ø±Ø§Ù‹! Ø§Ù†ØªÙ‡Øª Ù…Ø­Ø§ÙˆÙ„Ø§ØªÙƒ ({user_limit}).")
    else:
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        with st.chat_message("user"): st.markdown(final_prompt)
        
        pdf_txt = ""
        if up_pdf:
            reader = PyPDF2.PdfReader(up_pdf)
            for page in reader.pages: pdf_txt += page.extract_text()
            
        system_msg = f"""Ø£Ù†Øª Ù…Ø¯Ø±Ø³ {subject} Ø®Ø¨ÙŠØ± Ù„Ù„ØµÙ {level}.
        - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠØ© Ø§Ù„Ù…Ø­Ø¨Ø¨Ø©.
        - Ø§Ø³ØªØ®Ø¯Ù… LaTeX Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø¨ØµÙŠØºØ© $$...$$.
        - Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù†Øµ PDFØŒ Ø§Ø¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡: {pdf_txt[:2000]}
        - Ù„Ùˆ Ø·Ù„Ø¨ Ø±Ø³Ù…Ø© Ø£Ùˆ Ø§Ø­ØªØ§Ø¬ Ø§Ù„Ø£Ù…Ø± Ù„Ø±Ø³Ù… Ø§ÙƒØªØ¨: 'IMAGE_REQ'.
        - Ø¨Ø¹Ø¯ Ø¥Ø¬Ø§Ø¨ØªÙƒØŒ Ø§Ù‚ØªØ±Ø­ 3 Ø£Ø³Ø¦Ù„Ø© Ù‚ØµÙŠØ±Ø© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¨ÙØ§ØµÙ„ '###SUGGESTIONS###'."""

        with st.chat_message("assistant"):
            with st.spinner('ğŸ¤” Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±...'):
                try:
                    # ØªØ­Ø¶ÙŠØ± Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù†Øµ + ØµÙˆØ±Ø©)
                    user_content = [{"type": "text", "text": final_prompt}]
                    if up_img:
                        base64_img = base64.b64encode(up_img.getvalue()).decode('utf-8')
                        user_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}})

                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_content}]
                    )
                    full_res = response.choices[0].message.content
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø§Øª (ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ)
                    if "###SUGGESTIONS###" in full_res:
                        ans_part, sugg_part = full_res.split("###SUGGESTIONS###")
                        suggestions = [s.strip() for s in sugg_part.strip().split('\n') if s.strip()][:3]
                    else:
                        ans_part, suggestions = full_res, []

                    st.markdown(ans_part)
                    new_msg = {"role": "assistant", "content": ans_part}

                    if enable_voice:
                        speech = client.audio.speech.create(model="tts-1", voice="onyx", input=ans_part[:500])
                        new_msg["audio_content"] = speech.content
                        st.audio(new_msg["audio_content"])

                    if enable_image_gen and "IMAGE_REQ" in full_res:
                        img = client.images.generate(model="dall-e-3", prompt=f"Educational diagram about {final_prompt}", size="1024x1024")
                        st.image(img.data[0].url)

                    # Ø¹Ø±Ø¶ Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø§Øª
                    if suggestions:
                        st.markdown("---")
                        cols = st.columns(len(suggestions))
                        for i, s in enumerate(suggestions):
                            clean_s = s.replace("- ", "").replace("1. ", "").replace("2. ", "").replace("3. ", "")
                            if cols[i].button(clean_s, key=f"s_{i}"):
                                st.session_state.suggestion_clicked = clean_s
                                st.rerun()

                    st.session_state.messages.append(new_msg)
                    st.session_state.usage_counter += 1
                    save_history(st.session_state.history)
                    st.rerun()
                except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")
