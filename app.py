import streamlit as st
from openai import OpenAI
import json
import os
import datetime
import base64
import PyPDF2
import sys

# --- ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª ---
LIMITS = {"free": 5, "VIP10": 15, "ADMIN": 1000}

try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

st.set_page_config(page_title="Ù…Ø¹Ù‡Ø¯ÙŠ - Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ“", layout="wide")

# --- ğŸ¨ Ø§Ù„ØªØµÙ…ÙŠÙ… (CSS) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; }
    div[data-testid="stChatMessage"]:nth-child(odd) { background-color: #e3f2fd !important; border: 1px solid #bbdefb !important; border-radius: 15px; color: #000 !important; }
    div[data-testid="stChatMessage"]:nth-child(even) { background-color: #ffffff !important; border: 1px solid #e0e0e0 !important; border-radius: 15px; color: #000 !important; }
    div[data-testid="stChatMessage"] p { color: #000000 !important; font-size: 18px; }
    div.stButton > button { background: linear-gradient(45deg, #2563eb, #0ea5e9); color: white !important; border-radius: 12px; font-weight: 600; }
</style>
""", unsafe_allow_html=True)

# --- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
HISTORY_FILE = "chat_history.json"
if "usage_counter" not in st.session_state: st.session_state.usage_counter = 0

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f: return json.load(f)
        except: return {}
    return {}

def save_history(history_dict):
    to_save = {}
    for k, v in history_dict.items():
        msgs = [{"role": m["role"], "content": m["content"]} for m in v["messages"] if "audio_content" not in m]
        to_save[k] = {"title": v["title"], "messages": msgs}
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f: json.dump(to_save, f, ensure_ascii=False, indent=4)
    except: pass

if "history" not in st.session_state: st.session_state.history = load_history()
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = str(datetime.datetime.now())
    st.session_state.history[st.session_state.current_chat_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}

current_id = st.session_state.current_chat_id
st.session_state.messages = st.session_state.history[current_id]["messages"]
if "suggestion_clicked" not in st.session_state: st.session_state.suggestion_clicked = None
if "quiz_trigger" not in st.session_state: st.session_state.quiz_trigger = False

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# --- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙØµÙ„")
    subject = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø©:", ["Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡", "Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡", "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "Ø§Ù„Ø£Ø­ÙŠØ§Ø¡", "Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])
    level = st.selectbox("Ø§Ù„ØµÙ:", ["Ø§Ù„Ø«Ø§Ù„Ø« Ù…ØªÙˆØ³Ø·", "Ø§Ù„Ø±Ø§Ø¨Ø¹ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø®Ø§Ù…Ø³ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø³Ø§Ø¯Ø³ Ø¹Ù„Ù…ÙŠ", "Ø§Ù„Ø³Ø§Ø¯Ø³ Ø£Ø¯Ø¨ÙŠ"])
    
    st.markdown("---")
    user_code = st.text_input("ğŸ”‘ ÙƒÙˆØ¯ Ø§Ù„ØªÙØ¹ÙŠÙ„:", type="password")
    current_limit = LIMITS.get(user_code, LIMITS["free"])
    st.write(f"ğŸ“Š Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª: {st.session_state.usage_counter} / {current_limit}")
    st.progress(min(st.session_state.usage_counter / current_limit, 1.0))
    
    st.markdown("---")
    enable_voice = st.toggle("ğŸ”Š Ù‚Ø±Ø§Ø¡Ø© ØµÙˆØªÙŠØ©", value=False)
    enable_image_gen = st.toggle("ğŸ¨ Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ", value=False)
    
    if st.button("â• Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©", type="primary"):
        st.session_state.current_chat_id = str(datetime.datetime.now())
        st.session_state.history[st.session_state.current_chat_id] = {"title": "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", "messages": []}
        st.rerun()

    if st.button("ğŸ“ Ø§Ù…ØªØ­Ø§Ù† Ø³Ø±ÙŠØ¹"): st.session_state.quiz_trigger = True

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title(f"ğŸ“ Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø°ÙƒÙŠ: {subject}")

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "audio_content" in msg: st.audio(msg["audio_content"], format="audio/mp3")

with st.expander("ğŸ“ Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª"):
    c1, c2, c3 = st.columns(3)
    with c1: audio_in = st.audio_input("ØªØ³Ø¬ÙŠÙ„")
    with c2: img_in = st.file_uploader("ØµÙˆØ±Ø©", type=["jpg", "png"])
    with c3: pdf_in = st.file_uploader("PDF", type=["pdf"])

prompt_in = st.chat_input("Ø§Ø³Ø£Ù„ Ø£Ø³ØªØ§Ø°Ùƒ...")
final_prompt = None

if st.session_state.suggestion_clicked:
    final_prompt = st.session_state.suggestion_clicked
    st.session_state.suggestion_clicked = None
elif st.session_state.quiz_trigger:
    final_prompt = f"Ø§Ù…ØªØ­Ø§Ù† ÙÙŠ {subject}."
    st.session_state.quiz_trigger = False
elif prompt_in: final_prompt = prompt_input = prompt_in
elif audio_in:
    try:
        transcript = client.audio.transcriptions.create(model="whisper-1", file=("audio.wav", audio_in, "audio/wav"), language="ar")
        final_prompt = transcript.text
    except: pass

if final_prompt:
    if st.session_state.usage_counter >= current_limit:
        st.error(f"ğŸ›‘ Ø§Ù†ØªÙ‡Øª Ù…Ø­Ø§ÙˆÙ„Ø§ØªÙƒ ({current_limit}).")
    else:
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        with st.chat_message("user"): st.markdown(final_prompt)
        
        pdf_txt = ""
        if pdf_in:
            reader = PyPDF2.PdfReader(pdf_in)
            for page in reader.pages: pdf_txt += page.extract_text()

        # --- ğŸ§  Ù…Ù†Ø·Ù‚ Ø§Ù„ÙØµÙ„ Ø§Ù„Ù…Ø±Ù† (The Flexible Persona) ---
        system_logic = f"""Ø£Ù†Øª "Ø£Ø³ØªØ§Ø° Ù…Ø§Ø¯Ø© {subject}" Ù„Ù„ØµÙ {level}.
        
        Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø°ÙƒÙŠ Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:
        1. Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø¹Ù„Ù…ÙŠ: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¶Ù…Ù† {subject}ØŒ Ø£Ø¬Ø¨ Ø¨ØªØ¹Ù…Ù‚.
        2. Ø§Ù„ØªØ¯Ø§Ø®Ù„ Ø§Ù„Ø¹Ù„Ù…ÙŠ (Ø§Ù„Ù…Ù‡Ù…): Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¹Ù† Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø´ØªØ±Ùƒ (Ù…Ø«Ù„Ø§Ù‹ Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ© ÙˆØ£Ù†Øª ÙÙŠ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ØŒ Ø£Ùˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¡ ÙˆØ£Ù†Øª ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª)ØŒ Ø£Ø¬Ø¨ Ø¨Ø°ÙƒØ§Ø¡ ÙˆÙˆØ¶Ø­ Ù„Ù‡ ÙƒÙŠÙ ÙŠØ±ØªØ¨Ø· Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ù€ {subject}. Ù„Ø§ ØªØ±ÙØ¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù† Ø§Ù„Ø¹Ù„ÙˆÙ… Ø§Ù„Ù…ØªÙ‚Ø§Ø±Ø¨Ø©.
        3. Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„ØªØ§Ù…: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¹ÙŠØ¯Ø§Ù‹ ÙƒÙ„ÙŠØ§Ù‹ Ø¹Ù† Ø§Ù„Ø¹Ù„Ù… (Ø·Ø¨Ø®ØŒ Ø´Ø¹Ø±ØŒ Ø£Ø®Ø¨Ø§Ø± ÙÙ†Ø§Ù†ÙŠÙ†) ÙˆØ£Ù†Øª ÙÙŠ Ø¯Ø±Ø³ Ø¹Ù„Ù…ÙŠ:
           - Ø§Ø¹ØªØ°Ø± Ø¨Ù„Ù‡Ø¬Ø© Ø¹Ø±Ø§Ù‚ÙŠØ©: "ÙŠØ§ Ø¨Ø·Ù„ØŒ Ø£Ù†Ø§ Ø£Ø³ØªØ§Ø° Ø§Ù„Ù€{subject}ØŒ ÙˆÙ…Ø§ Ø£Ø±ÙŠØ¯ Ù†Ø¶ÙŠØ¹ ÙˆÙ‚ØªÙ†Ø§ Ø¨ØºÙŠØ± Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø­ØªÙ‰ Ù†Ø¶Ø¨Ø· Ø§Ù„Ù…Ø§Ø¯Ø©. Ø®Ù„ÙŠÙ†Ø§ Ø¨Ù€{subject}!"
        
        Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
        - Ø§Ù„Ù„Ù‡Ø¬Ø©: Ø¹Ø±Ø§Ù‚ÙŠØ© Ù…Ø­Ø¨Ø¨Ø©.
        - Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª: Ø§Ø³ØªØ®Ø¯Ù… LaTeX Ø¨ØµÙŠØºØ© $$...$$.
        - Ù„Ùˆ Ø·Ù„Ø¨ Ø±Ø³Ù…Ø© Ø§ÙƒØªØ¨ 'IMAGE_REQ'.
        - Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø§Øª: Ø¶Ø¹ 3 Ø£Ø³Ø¦Ù„Ø© Ø¨Ø¹Ø¯ '###SUGGESTIONS###'."""

        with st.chat_message("assistant"):
            with st.spinner('ğŸ¤” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...'):
                try:
                    content_list = [{"type": "text", "text": final_prompt}]
                    if img_in:
                        b64 = base64.b64encode(img_in.getvalue()).decode('utf-8')
                        content_list.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})

                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "system", "content": system_logic}, {"role": "user", "content": content_list}]
                    )
                    full_res = response.choices[0].message.content
                    
                    if "###SUGGESTIONS###" in full_res:
                        answer, suggs = full_res.split("###SUGGESTIONS###")
                        s_list = [s.strip() for s in suggs.strip().split('\n') if s.strip()][:3]
                    else:
                        answer, s_list = full_res, []

                    st.markdown(answer)
                    msg_obj = {"role": "assistant", "content": answer}

                    if enable_voice:
                        speech = client.audio.speech.create(model="tts-1", voice="onyx", input=answer[:500])
                        msg_obj["audio_content"] = speech.content
                        st.audio(msg_obj["audio_content"])

                    if enable_image_gen and "IMAGE_REQ" in full_res:
                        img_gen = client.images.generate(model="dall-e-3", prompt=f"Scientific diagram about {final_prompt}", size="1024x1024")
                        st.image(img_gen.data[0].url)

                    if s_list:
                        st.markdown("---")
                        cols = st.columns(len(s_list))
                        for i, s in enumerate(s_list):
                            clean = s.replace("- ", "").replace("1. ", "").replace("2. ", "").replace("3. ", "")
                            if cols[i].button(clean, key=f"btn_{i}"):
                                st.session_state.suggestion_clicked = clean
                                st.rerun()

                    st.session_state.messages.append(msg_obj)
                    st.session_state.usage_counter += 1
                    save_history(st.session_state.history)
                    st.rerun()
                except Exception as e: st.error(f"Error: {e}")
